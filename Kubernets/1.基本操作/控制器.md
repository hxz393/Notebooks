# 控制器

## ReplicationController

下面简称RC.可以通过kubectl api-resources命令查看所有缩写.

### 创建RC

创建一个最简化运行3个pod副本的RC配置如下:

```sh
[root@server4-master ~]# vi kubia-rc.yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: kubia
spec:
  replicas: 3
  selector:
    app: kubia
  template:
    metadata:
      labels:
        app: kubia
    spec:
      containers:
      - name: kubia
        image: luksa/kubia
        ports:
        - containerPort: 8080
[root@server4-master ~]# kubectl create -f kubia-rc.yaml 
replicationcontroller/kubia created
```

标签选择器需要与pod的labels标签匹配,否则RC会一直启动新容器.假如不指定选择器selector,RC会根据pod模板中的标签自动配置.

运行后K8s会创建一个名为kubia的新RC,并且始终运行3个实例.没有足够pod时会根据模板创建新pod.下面手动删除一个pod,RC会立即重建一个新的容器:

```sh
[root@server4-master ~]# kubectl delete po kubia-wtlrp
pod "kubia-wtlrp" deleted
[root@server4-master ~]# kubectl get po
NAME          READY   STATUS        RESTARTS   AGE
kubia-2vpxd   1/1     Running       0          105s
kubia-9fqql   1/1     Running       0          105s
kubia-slltr   1/1     Running       0          22s
kubia-wtlrp   1/1     Terminating   0          105s
```

如果有节点故障,那么RC会在新的节点上启动节点故障上的pod,之后节点故障恢复也不会再迁移回去.

### 查看RC

查询当前运行的所有RC:

```sh
[root@server4-master ~]# kubectl get rc
NAME    DESIRED   CURRENT   READY   AGE
kubia   3         3         3       9m37s
```

查询具体RC的信息同样使用kubectl describe命令:

```sh
[root@server4-master ~]# kubectl describe rc kubia 
Name:         kubia
Namespace:    default
Selector:     app=kubia
Labels:       app=kubia
Annotations:  <none>
Replicas:     3 current / 3 desired
pods Status:  3 Running / 0 Waiting / 0 Succeeded / 0 Failed
```

### 修改模板

可以通过kubectl edit rc命令来修改RC的pod模板,例如修改模板中的标签选择器和副本数:

```sh
[root@server4-master ~]# kubectl edit rc kubia
spec:
  replicas: 2
  selector:
    app: kubia1
  template:
    metadata:
      labels:
        app: kubia1
"/tmp/kubectl-edit-2608748675.yaml" 46L, 1157C written
replicationcontroller/kubia edited
```

查看pod和Label发现共有5个pod,新旧标签一同存在:

```sh
[root@server4-master ~]# kubectl get po --show-labels 
NAME          READY   STATUS    RESTARTS   AGE   LABELS
kubia-2c44j   1/1     Running   0          56s   app=kubia1
kubia-2vpxd   1/1     Running   0          40m   app=kubia
kubia-9fqql   1/1     Running   0          40m   app=kubia
kubia-ggk2j   1/1     Running   0          56s   app=kubia1
kubia-slltr   1/1     Running   0          38m   app=kubia
```

### 水平缩放

使用scale命令能修改RC配置中spec.replicas字段的数值,达到扩缩容效果:

```sh
[root@server4-master ~]# kubectl scale rc kubia --replicas=1
replicationcontroller/kubia scaled
[root@server4-master ~]# kubectl get pod --show-labels
NAME          READY   STATUS        RESTARTS   AGE     LABELS
kubia-2c44j   1/1     Running       0          5m18s   app=kubia1
kubia-ggk2j   1/1     Terminating   0          5m18s   app=kubia1
```

### 删除RC

当使用delete删除RC时,pod也会被删除.可以指定--cascade=orphan选项来删除RC同时保持pod运行:

```sh
[root@server4-master ~]# kubectl delete rc kubia --cascade=orphan
replicationcontroller "kubia" deleted
```

之后可以通过标签选择器创建新的RC或RS将它们再次管理起来.



## ReplicaSet

下面简称RS.RS和RC都是依赖pod标签选择器来控制.

### 创建RS

建立yaml配置文件并发布.和RC配置不同的是apiVersion版本, kind类型和标签选择器样式:

```sh
[root@server4-master ~]# vi kubia-rs.yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: kubia
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      labels:
        app: kubia
    spec:
      containers:
      - name: kubia
        image: luksa/kubia
        ports:
        - name: http
          containerPort: 80
[root@server4-master ~]# kubectl create -f kubia-rs.yaml
replicaset.apps/kubia created
```

### 标签选择

标签选择器和pod中使用的一样,不过写法有些不同.例如通过matchLabels匹配单个标签:

```sh
[root@server4-master ~]# vi kubia-rs.yaml
spec:
  selector:
    matchLabels:
      app: kubia
```

例如通过matchExpressions表达式同时选择两个不同app值的标签:

```sh
[root@server4-master ~]# vi kubia-rs.yaml
spec:
  selector:
    matchExpressions:
      - key: app
        operator: In
        values:
          - kubia
          - kubia1
```

operator还可以使用其他运算符: NotIn(不在列表中),Exists(匹配Key),DoesNotExist(反向匹配Key)

如果指定了多个表达式,所有表达式匹配结果都必须为true才能使选择器与pod匹配.

如果同时使用matchLabels和matchExpressions,则所有标签都必须匹配.



## DaemonSet

下面简称DS.DS和RS相比多了一个nodeSelector选择器,DS依赖节点标签选择器来控制.

### 创建DS

首先给一个节点打上标签disk='ssd':

```sh
[root@server4-master ~]# kubectl label node server5-node1 disk='ssd'
node/server5-node1 labeled
```

然后建立YAML配置文件并启动:

```sh
[root@server4-master ~]# vi kubia-ds.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ds-ssd
spec:
  selector:
    matchExpressions:
      - key: app
        operator: In
        values:
          - kubia
  template:
    metadata:
      labels:
        app: kubia
    spec:
      nodeSelector:
        disk: ssd
      containers:
      - name: kubia
        image: luksa/kubia
[root@server4-master ~]# kubectl create -f kubia-ds.yaml 
daemonset.apps/ds-ssd created
```

DS还可以配置更新机制,相关配置定义在spec.update-Strategy字段,方式为RollingUpdate(滚动更新)或OnDelete(删除再更新).回滚操作同样支持.

### 验证

将server6-node2也打上ssd标签后再查看信息:

```sh
[root@server4-master ~]# kubectl label node server6-node2 disk='ssd'
[root@server4-master ~]# kubectl get pod -o wide
NAME           READY   STATUS    RESTARTS   AGE     IP               NODE     
ds-ssd-drb2z   1/1     Running   0          4m19s   10.244.191.199   server5-node1  
ds-ssd-f6cwh   1/1     Running   0          23s     10.244.244.199   server6-node2  
```

去除节点标签后运行在其上的pod会立即删除:

```sh
[root@server4-master ~]# kubectl label node server6-node2 disk-
[root@server4-master ~]# kubectl label node server5-node1 disk-
[root@server4-master ~]# kubectl get ds
NAME     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
ds-ssd   0         0         0       0            0           disk=ssd        7m52s
```



## Job

Job使用api为batch/v1.需要明确地将重启策略设置为OnFailure或Nerver,防止容器在完成任务时重新启动.

### 创建Job

这里调用了一个运行120秒的进程然后退出.指定restartPolicy属性为OnFailure(默认为Always):

```sh
[root@server4-master ~]# vi kubia-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-job
spec:
  template:
    metadata:
      labels:
        app: batch-job
    spec:
      restartPolicy: OnFailure
      containers:
      - name: main
        image: luksa/batch-job
[root@server4-master ~]# kubectl create -f kubia-job.yaml
```

当Job任务完成后状态显示为Completed:

```sh
[root@server4-master ~]# kubectl get jobs
NAME        COMPLETIONS   DURATION   AGE
batch-job   1/1           119s       2m59s
[root@server4-master ~]# kubectl get pod
NAME                 READY   STATUS      RESTARTS   AGE
batch-job--1-2ddkr   0/1     Completed   0          3m10s
```

出于查询日志的需求,完成任务的pod不会自动删除,可以通过删除创建的Job来一同删除.

### 多次运行

可以在Job中配置创建多个pod实例,设置completions和parallelism属性来以并行或串行方式运行.

顺序运行用于一个Job运行多次的场景,例如设置顺序运行五个pod,每个pod成功完成后工作才结束:

```sh
[root@server4-master ~]# vi kubia-job.yaml
spec:
  completions: 5
[root@server4-master ~]# kubectl create -f kubia-job.yaml
[root@server4-master ~]# kubectl get jobs
NAME        COMPLETIONS   DURATION   AGE
batch-job   0/5           12s        12s
```

设置并行运行需要多加一个parallelism参数设置并行启动pod数目:

```sh
[root@server4-master ~]# vi kubia-job.yaml
spec:
  completions: 5
  parallelism: 3
[root@server4-master ~]# kubectl delete job batch-job 
[root@server4-master ~]# kubectl create -f kubia-job.yaml
[root@server4-master ~]# kubectl get po
NAME                 READY   STATUS    RESTARTS   AGE
batch-job--1-5ghsj   1/1     Running   0          39s
batch-job--1-mctcz   1/1     Running   0          39s
batch-job--1-znpbq   1/1     Running   0          39s
```

Job的并行任务数同样可以通过scale命令来修改

### 限制条件

可以通过activeDeadlineSeconds属性来限制pod的运行时间.如果超时没完成,系统会尝试终止pod并标记失败.

还能配置Job被标记为失败前重试的次数,通过spec.backoffLimit字段,默认为6次.



## CronJob

下面简称CJ.K8s通过CJ中配置的Job模板创建Job资源.

### 创建CJ

创建一个每十五分钟运行一次的Job:

```sh
[root@server4-master ~]# vi kubia-cj.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: 15job
spec:
  schedule: "0,15,30,45 * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: 15job
        spec:
          restartPolicy: OnFailure
          containers:
          - name: main
            image: luksa/batch-job
[root@server4-master ~]# kubectl create -f kubia-cj.yaml 
[root@server4-master ~]# kubectl get cj
NAME    SCHEDULE             SUSPEND   ACTIVE   LAST SCHEDULE   AGE
15job   0,15,30,45 * * * *   False     0        <none>          16s
```

其中schedule段五个设置分别是: `分钟 小时 每月日期 月 星期`

### 超时设置

可以通过startingDeadlineSeconds字段来设置预定运行超时时间,例如不能超过预定时间15秒后运行:

```sh
[root@server4-master ~]# vi kubia-cj.yaml
spec:
  startingDeadlineSeconds: 15
```

不管任何原因,时间超过了15秒而没启动任务,任务将不会运行并显示失败.

### 其他设置

其他一些spec字段可嵌套使用字段:

- concurrencyPolicy: 并发执行策略,用于定义前一次作业运行尚未完成时是否以及如何运行后一次的作业.可选值Allow, Forbid或Replace.

- failedJobHistoryLimit: 为失败的任务执行保留的历史记录数,默认1.

- successfulJobsHistoryLimit: 为成功的任务执行保留的历史记录数,默认3.

- startingDeadlineSeconds: 设置超时时间,超时没完成任务会被记入错误历史记录.

- suspend: 是否挂起后续的任务执行,默认false,对运行中的作业不会产生影响.