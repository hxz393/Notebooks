# 自动伸缩

## 定义

Horizontal Pod Autoscaling(HPA)横向自动伸缩,指由控制器管理的pod副本数量,根据当前负载情况自动触发水平扩展或缩容的行为.

自动伸缩过程可分为三个步骤:

- 获取被伸缩资源对象所管理的所有pod度量

  Autoscaler本身不采集pod度量数据,而是从cAdvisor agent获取,由Heapster聚合,被HPA请求调用.

- 计算使度量数值到达(或接近)所指目标数值所需的pod数量

  Autoscaler一旦获得它所调整的资源所管辖pod的全部度量,便利用这些度量计算所需的副本数量.

  当只有一个度量时,计算副本数只要将所有pod的度量求和后除以目标值,再向上取整即可.

  当有多个度量时,会分别计算每个度量所需的副本数,取最大值.

- 更新被伸缩资源的replicas字段

  Autoscaler控制器通过Scale子资源来修改被伸缩资源的replicas字段,来启动更多pod或删除多余pod.

HPA不允许设置最小副本数为0



## 基于CPU使用率

就Autoscaler而言,CPU使用率通过pod的CPU请求量与实际使用量对比得到,所以对CPU的requests必须设置:

```sh
[root@server4-master ~]# vi dp.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kubia
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - name: nodejs
        image: luksa/kubia
        ports:
        - name: http
          containerPort: 8080
        resources:
          requests:
            cpu: 100m
[root@server4-master ~]# kubectl create -f dp.yaml
deployment.apps/kubia created
```

创建一个HPA对象指向该Deploy.HPA中设置目标CPU使用率为30%,指定副本最小和最大数量,Autoscaler会在Deploy上持续调整副本数量以使CPU使用率接近30%:

```sh
[root@server4-master ~]# kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5
horizontalpodautoscaler.autoscaling/kubia autoscaled
[root@server4-master ~]# kubectl get hpa
NAME    REFERENCE          TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
kubia   Deployment/kubia   <unknown>/30%   1         5         3          63s
[root@server4-master ~]# kubectl get deployment
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
kubia   3/3     3            3           2m13s
```

由于三个pod没有活动,CPU使用接近0.等待5分钟后,Autoscaler会将它们收缩到1个副本.自动扩容操作等待时间为3分钟.



## 基于内存使用

基于内存的自动伸缩比基于CPU的困难得多,主要原因在于扩容之后原有的pod需要有办法释放内存.这只能由应用完成,系统无法代劳.

系统只能杀死并重启应用,期望它能比之前少占用一些内存.在Autoscaler上会一直操作扩容,直到达到配置的最大pod数量.



## 基于其他度量

定义HPA需要三个要素配合:定义metric类型,被监控的资源类型,资源的目标使用量.

可以在HPA对象中使用三种度量:

- Resource度量类型

  Resource类型基于一个资源度量做出自动伸缩决策.

  例如基于cpu使用量作为度量:

  ```sh
  spec:
    maxReplicas: 5
    metrics:
    - resource:
        name: cpu
        targetAverageUtilization: 30
  ```

- Pods度量类型

  Pods类型用来引用任何其他种类(包括自定义的)与pod直接相关的度量.比如每秒查询次数(QPS),或消息队列中消息数量.

  例如使HPA控制的RS控制器下所有pod的平均qps维持100的水平:

  ```sh
  spec:
    metrics:
    - type: Pods
      resource:
        name: qps
        targetAverageValue: 100
  ```

- Object度量类型

  Object度量类型用来指非直接关联pod的度量,例如Ingress对象.在使用Object度量类型时,Autoscaler只会从这单个对象中获取单个度量数据.

  例如使用Ingress对象frontend的latencyMillis的目标值作为度量,度量超过目标值太多,则会对Deploy资源进行扩容:

  ```sh
  spec:
    metrics:
    - type: Object
      resource:
        metricName: latencyMillis
        target:
          apiVersion: extensions/v1beta1
          kind: Ingress
          name: frontend
          targetValue: 20
        scaleTargetRef:
          apiVersion: extensions/v1beta1
          kind: Deployment
          name: hpans
  ```

不是所有度量都适合作为自动伸缩的基础,在决定基于自定义度量来伸缩时,需要考虑好pod数量变化对度量值的影响.



## 纵向自动伸缩

不是所有应用都能被横向伸缩.比如有些pod运行到特定单节点,这时需要纵向伸缩.

纵向伸缩通过改变pod manifest的字段,来配置pod资源请求.可以从官方github下载部署.下面是一个VPA示例:

```sh
apiVersion: autoscaling.k8s.io/v1beta2
kind: VerticalPodAutoscaler
metadata:
  name: nginx-vpa
  namespace: vpa
spec:
  targetRef:
    apiVersion: "apps/v1"
    kind: Deployment
    name: nginx
  updatePolicy:
    updateMode: "Off"
  resourcePolicy:
    containerPolicies:
    - containerName: "nginx"
      minAllowed:
        cpu: "250m"
        memory: "100Mi"
      maxAllowed:
        cpu: "2000m"
        memory: "2048Mi"
```

VPA同样需要metrics-server配合,不能与HPA一起使用.



## 节点自动伸缩

Cluster Autoscaler负责在节点资源不足时,自动部署新节点,也会在节点长时间使用率低下情况下下线节点.目前节点自动伸缩可支持:GKE, GCE, AWS, AZURE.

显然不是随意一个节点都能满足pod的需求,因此云服务提供者通常把相同特性的节点聚合成组.当请求新节点时,需要指明节点类型.

归还节点是通过监控所有节点上请求的CPU与内存来实现.如果由系统pod运行在该节点上(不算DaemonSet部署的服务),节点不会被释放.也就是只有Cluster Autoscaler知道节点上运行的pod能调度到其他节点,该节点才能释放.释放节点前首先会被标记为不可调度,然后把其上的pod疏散到其他节点.

下线节点过程中如果需要指定最少需要维持运行的pod数量,可以用PodDisruptionBudge资源来控制.

