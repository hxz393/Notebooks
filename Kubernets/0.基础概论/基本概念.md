# 基本概念

## K8s介绍

Kubernetes源于谷歌内部的Borg,是一个面向应用的容器集群部署和管理系统.Kubernetes的目标旨在消除管理计算,网络和存储这些基础设施的负担,将底层基础设施抽象,这样做同时简化了应用的开发,部署,以及对开发和运维团队的管理.K8s还提供基础平台,用于构建定制化的工作流程和高级的自动化任务.

从运维角度来看,只要服务器上部署了K8s,不再需要安装其他依赖服务就能运行应用程序.Kubernetes具有以下几个重要特性:

- 自动装箱

  构建于容器之上,基于资源依赖及其他约束自动完成容器部署且不影响其可用性.通过调度机制混合关键型应用和非关键型应用的工作负载于同一节点以提升资源利用率.在K8s中所有工作节点公开为一个部署平台,开发人员不需要了解组成集群的服务器.如果需要使用一些特性节点来运行程序,可以通过节点标签来选择.

- 健康检查和自我修复

  K8s会监控应用程序组件和运行节点,支持容器故障后自动重启,节点故障后重新调度容器,健康状态检查失败后重新创建等自愈机制.

- 水平扩展

  支持通过简单的命令手动水平扩展.以及基于硬件资源负载率的自动水平扩展机制.如K8s运行在云基础设施上,可以根据程序使用资源情况和需要,自动添加或缩减节点.

- 服务发现和负载均衡

  K8s通过KubeDNS(或CoreDNS)为系统内置了服务发现功能.它为每个Service配置DNS名称,允许集群内的客户端直接使用名称访问,而Service则通过iptables或ipvs内建了负载均衡机制.

- 自动发布和回滚

  K8s支持灰度更新应用程序或配置信息.它会确保实例不会同时停止,一旦有故障发生,会立即自动执行回滚.

- 密钥和配置管理

  K8s的ConfigMap实现了配置数据与Docker镜像分离,对配置做出变更时无需重构镜像.此外对于敏感数据如密码和密钥等,有专门的Secret对象来存放.

- 存储编排

  K8s支持pod对象按需自动挂载不同类型的储存系统,比如本地储存,云储存和网络储存系统.

- 批量处理执行

  除了服务型应用,K8s还支持批处理作业和持续集成.



## 集群构架

一个k8s集群由很多节点组成,这些节点被分为两种类型:

- 主节点(**Master**)
  集群的控制节点,承载控制和管理整个集群系统.负责如为用户暴露API,跟踪其他服务器的健康状态,以最优的方式调度工作负载,以及编排其他组件之间的通信等任务.可以运行多个Master以提高可用性.

- 工作节点(**Node**)
  运行用户实际部署的应用,由Master管理.负责接收来自Master的工作指令,并依据指令创建或销毁pod对象,以及调整网络规划以合理地路由和转发流量等.Node运行在Linux系统上,可以是物理机或虚拟机.

K8s将所有Node的资源集结在一起,形成一台超级服务器,用户将应用部署在其上时,Master会使用调度算法将其自动指派指某个特定的Node运行.

### 主节点

主节点的控制面板负责控制并使得整个集群正常运转.它包含多个组件,组件可以运行在单个主节点上或者通过副本分别部署在多个主节点以确保高可用性.这些组件是:

- API 服务器(kube-apiserver)
  负责其他控制面板组件的通信,提供了HTTP Rest接口的关键服务进程,是集群的前端接口.

- Scheculer 调度器(kube-scheduler)
  调度应用,为应用的每个可部署组件分配一个工作节点.

- Controller Manager 控制器管理器(kube-controller-manager)
  执行集群级别的功能,如复制组件,持续跟踪工作节点,处理节点失败等,保证资源处于预期状态.

- etcd 分布式持久化储存
  一个可靠的分布式数据储存,能持久化储存群集配置和各种资源的状态信息.当数据发生变化时,etcd会快速地通知相关组件.

### 工作节点

工作节点是运行容器化应用的机器.运行,监控和管理应用服务的任务是由以下组件完成:

- 容器运行时(Container runtime)
  负责镜像管理以及pod和容器的真正运行(CRI).默认为Docker Engine,也可用其他类型容器引擎.

- Kubelet(kubelet)
  与API服务器通信,并管理它所在节点的容器,与容器运行时交互,是Node的客户端.当调度器确定在某个Node上运行pod后,会将具体配置信息发送给Kubelet来创建和运行容器,并向Master报告运行状态.同时也负责Volume(CVI)和网络(CNI)的管理.

- Proxy 服务代理(kube-proxy)
  每个Node都会运行Proxy服务,它负责将访问Service的数据流转发到后端容器(服务发现).如果有多个pod副本,还负责组件之间的负载均衡网络流量.

### 发布流程

在Kubernets中发布应用流程如下:

- 首先需要将应用打包进一个或多个容器镜像.
- 将打包好的镜像推送到镜像仓库.
- 将应用描述发布到API服务器.
- API服务器通过调度器指示可用工作节点上的Kubelet拉取镜像运行容器.

应用运行起来后Kubernets的工作:

- API服务器会不断确认应用部署状态是否和描述一致,如果实例之一停止了正常工作,比如进程崩溃或停止响应,Kubernetes会自动重启它.

- 如果整个工作节点宕机无法访问,故障节点上运行的所有容器会调度到新节点运行.

- 当程序运行时,可以手动随时调整副本数量,也可根据节点状态实时指标自动调整副本数.
- 当容器在集群内频繁调度时,服务代理将确保服务始终可用.



## pod

pod是一组并置的容器,代表了k8s中的基本构建模块.也可以理解为一个应用程序的单一运行实例,由共享资源且关系紧密的一个或多个应用容器组成,并为它们提供相同的环境.这些进程就好像全部运行于一个容器中一样,同时又保持着隔离性.

在实际中并不会单独部署容器,更多是针对一组pod的容器进行部署的操作.当一个pod包含多个容器时,这些容器总是运行于同一个工作节点上,一个pod绝不会跨越多个工作节点.

pod拥有以下特点:

- 同pod中容器部分隔离

  Kubernetes通过配置docker来让一个pod内的所有容器共享相同的Linux命名空间,它们共享相同的主机名和网络接口,容器之间能通过IPC进行通信.其他的MNT,USR和PID名称空间可以分别独立.

- 同pod中容器共享网络命名空间

  在pod中的容器处于同一个网络命名空间中,意味着共享pod的IP地址和端口.所以需要注意容器绑定的端口号不能相同,否则会导致端口冲突.同一pod中的容器可以直接通过回环口(loopback)来通信.

- 平坦的pod间网络

  K8s集群中所有的pod都在同一个共享网络地址空间中,pod之间可以直接通过pod的IP地址来实现互相访问.不管实际节点的网络拓扑结构如何,都不需要NAT网络地址转换,就像在局域网中一样.

### 组织pod

虽然pod看上去像一个独立机器,但不应该将多个应用填充到一个pod中.每个pod只应包含紧密相关的组件或进程,保持pod的轻量级,这样可以尽可能多创建pod:

- 将多层应用分散到多个pod

  一个典型的应用由前端和后端数据库组成,如果将两者放入同一个容器,那么它们作为整体只能在一个节点运行,无法利用另外节点的计算资源.把他们拆分后可以在不同节点分别布置前端和后端应用,提高基础构架的利用率.

- 基于扩缩容考虑

  pod是扩缩容的基本单位,通常前端和后端组件具有不同的扩缩容需求,后端数据库比无状态的前端更难扩展,因此需要分开部署到单独pod中.

- 使用Sidecar容器

  将多个容器添加到单个pod的主要原因是:应用可能由一个主进程和多个辅助进程组成.此时辅助程序所在的容器被称为Sidecar容器,通常用来做日志收集,数据处理,储存与通信等.

- pod使用多个容器

  如果多个容器作为整体不可分离,必须一起进行扩缩容时,才考虑装入同一个pod中.

### Pause容器

每个pod都有一个特殊的被成为根容器的Pause容器,Pause容器对应的镜像属于Kubernetes平台的一部分,剩余是用户业务容器.

引入业务无关且不易死亡的Pause容器作为pod根容器,以它的状态代表整个容器组的状态,能让我们更简单地判断运行状态.它的声明周期和pod绑定,如果基础pod在这期间被关闭,Kubelet会重新创建它以及pod的所有容器.

另一层面如果pod中有多个容器,通过Pause容器挂接外部卷,共享Pause容器IP,简化了业务容器之间的通信问题.

### 生命周期

pod对象有5种状态:

- Pending

  API Server创建了pod资源对象并已存入etcd中,但它尚未被调度完成,或仍处于下载镜像中.

- Running

  pod已被调度到某节点,所有容器都已被Kubelet创建完成.

- Succeeded

  pod中所有容器都已成功终止且不会被重启.

- Failed

  所有容器都已终止,至少有一个容器终止失败,返回了非0的退出状态.

- Unknown

  API Server无法正常获取pod对象的状态信息,通常是由于节点失联造成.

### 描述文件

pod或其他资源通常是通过向REST API提供JSON或YAML描述文件来创建.可以通过kubectl get命令加入-o yaml参数来查看YAML定义:

```sh
[user1@server6 ~]$ kubectl get pod kubia -o yaml
apiVersion: v1
kind: pod
metadata:
  creationTimestamp: "2021-11-02T21:50:57Z"
  labels:
    run: kubia
  name: kubia
```

pod定义文件中的结构几乎在所有K8s资源中都可以找到:

- apiVersion: K8s API版本.当前具体资源使用API版本可以通过kubectl api-resources命令查到.
- kind: 资源类型.
- metadata: 元数据,包括名称,命名空间,标签和容器其他信息.
- spec: 包括pod内容的实际说明,例如容器和卷.
- status: 包含运行中pod的当前信息,例如容器状态和内部IP信息.

可以通过kubectl explain pods命令看到关于yaml中各属性的说明.需要了解详细可以直接查看属性,比如kubectl explain pod.status:

```sh
[user1@server6 ~]$ kubectl explain pod.status

FIELDS:
   conditions   <[]Object>
     Current service state of pod. More info:
     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-conditions

   containerStatuses    <[]Object>
     The list has one entry per container in the manifest. Each entry is
     currently the output of `docker inspect`. More info:
     https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#pod-and-container-status
```



## 控制器

控制器主要工作是通过标签管理pod,它们是k8s上的一类对象,包括ReplicationController, ReplicaSet, Deployment, StatefulSet, Job等.控制器的定义通常由期望的副本数量,pod模板和标签选择器组成.

### ReplicationController

ReplicationController用来确保pod始终保持运行状态,它主要通过pod标签用来控制副本数量.RC是用于复制和重新调度节点的最初组件,后引入ReplicaSet来代替它,不推荐再使用.

RC主要有三个部分组成:

- label selector(标签选择器): 用于确定RC作用域中的pod.
- replica count(副本个数): 指定应运行的pod数量.
- pod template(pod模板): 用于创建新的pod副本.

RC的配置可以随时修改:

- 修改副本数量会立即生效.
- 更改标签选择器和pod模板对运行中pod没有影响,只会使现有的pod脱离RC的控制范围.
- 修改模板仅影响由此RC创建的新pod.
- 如果更改一个pod的标签,那么它不再归RC管理,RC会自动启动一个新的pod来代替它.

### ReplicaSet

RS的行为和用法与RC几乎完全相同.和RC相比,RS的选择器还允许反向选择,或通过标签key来选择pod.例如选择所有带env标签的pod(env=*).

通常不会直接创建RS对象,而是通过创建Deployment资源时自动创建.Deployment通过RS来管理pod的多个副本.

### DaemonSet

使用DS来设置在集群中每个节点固定运行一个pod,通常用来部署系统服务,比如用来收集日志或者做资源监控.

也可以通过nodeSelector选择器来选择一组节点作为部署节点,而不是默认的所有节点.

如果被选择器选择的节点被设置为不可调度,DS依然会绕过调度器将pod部署到这种节点上.

### Deployment

最常用的Controller,可以管理pod的多个副本并确保pod按照期望的状态运行.

### StatefuleSet

保证pod的每个副本在整个生命周期中名称时不变的,其他Controller不提供这个功能.当某个pod发生故障需要删除并重启,pod的名称会发生变化.同时StatefuleSet会保证副本按照固定的顺序启动,更新或删除.

### Job

Job用来执行一个可完成的任务,进程终止之后不会再次启动.

在发生节点故障时,该节点上由Job管理的pod将重新安排到其他节点运行.如果节点本身异常退出(返回错误退出代码时),可以将Job配置为重新启动容器,由Job管理的pod会一直被重新安排直到任务完成为止.

### CronJob

可以创建CronJob资源来通过cron格式时间表,设置一个定时运行的Job任务.



## 服务资源

在K8s中不再能用记录pod IP方式让pod间互相通信,因为pod是活动的,会随着调度分配更换IP地址.K8s提供一种叫服务的资源,来解决pod间通信问题.每个Service其实就是微服务构架中的一个微服务.

服务的主要工作通过标签选择器选定一组pod对象,并为这组pod提供单一不变的接入点(固定IP),客户端通过访问此地址来访问后面任一pod对象.

若集群存在DNS附件,它会在Service创建时为其自动配置一个DNS名称以便客户端进行服务发现.本质上来说Server是一个四层代理服务器.

运行在每个Node上的Proxy进程其实就是一个智能的软件负载均衡器,在内部实现服务的负载均衡与会话保持机制.

### 从外部访问服务

有几种方式可以从外部访问服务:

- 将服务类型设置成NodePort

  每个集群节点都会在节点上打开一个端口,并将在该端口的流量转发重定向到基础服务.该服务仅在内部集群IP和端口上才可访问,但也可通过所有节点上的专用端口访问.

- 将服务的类型设置成LoadBalance

  NodePort类型的一种扩展,使得服务器可以通过一个专用的负载均衡器来访问,负载均衡器由云基础设施提供.负载均衡器将流量重定向到跨所有节点的节点端口,客户通过负载均衡器的IP连接到服务.

- 创建一个Ingress资源

  通过一个IP地址公开多个服务,他运行在HTTP层(第7层)因此可以提供更多功能.

### 外部连接的特性

当客户通过节点端口连接到服务时,随机选择的pod并不一定在接收连接的同一节点上运行,例如接收服务pod运行在node1,而服务在node2,必然会造成不必要的跳转.可以通过将服务配置为仅将外部通信重定向到接收连接节点上运行的pod.

具体操作是修改服务spec.externalTrafficPolicy为Local.假如节点上没有本地pod存在则连接将挂起,因此需要确保负载平衡器将连接转发给至少具有一个pod的节点.

有一个问题是,原先均匀分配给pod的流量,变为按节点平均分配.假如一个节点一个pod,另一个节点两个pod,原先每个pod接收流量为1/3,设置流量不转发后,变成一个pod承担1/2流量,另外两个分别承担1/4流量.

在没配置流量不转发,当通过节点端口接收到连接时,会对数据包执行源网络地址转换(SNAT),因此数据包的源IP将发生更改,后端pod无法看到实际的客户端IP.这种时候上面的配置能保留客户端IP,因为接受连接的节点和目标pod节点之间没有额外跳跃.

### 排除连接故障

首先确保从集群内连接到服务的集群IP,不要通过ping来判断服务是否可访问,集群IP是虚拟IP.
如果已经定义了就绪探针,确保返回成功,否则该pod不会成为服务一部分.
要确认某个容器是服务的一部分,使用get endpoints来检查响应的端点对象.
如果通过FQDN来访问服务没用,查看是否可以使用集群IP访问.
尝试直接连接到pod IP以确认pod正在接收正确端口上的连接.
如果甚至无法通过pod的IP访问应用,确保应用不是仅绑定到本地主机.

